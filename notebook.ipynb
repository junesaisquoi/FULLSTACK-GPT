{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3fa054",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 15\u001b[0m\n\u001b[0;32m      6\u001b[0m llm \u001b[38;5;241m=\u001b[39m ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      8\u001b[0m memory \u001b[38;5;241m=\u001b[39m ConversationSummaryBufferMemory(\n\u001b[0;32m      9\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m     10\u001b[0m     max_token_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m,\n\u001b[0;32m     11\u001b[0m     memory_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     return_messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     )\n\u001b[1;32m---> 15\u001b[0m \u001b[43mprompt\u001b[49m \u001b[38;5;241m-\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m     16\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful AI assistant to a human\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     17\u001b[0m     MessagesPlaceholder(variable_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     18\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{question}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     19\u001b[0m ])\n\u001b[0;32m     21\u001b[0m chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[0;32m     22\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m     23\u001b[0m     memory\u001b[38;5;241m=\u001b[39mmemory,\n\u001b[0;32m     24\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m     25\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m chain\u001b[38;5;241m.\u001b[39mpredict(question\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy name is Junie\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant to a human\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Junie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67da43ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI assistant talking to a human.\n",
      "\n",
      "System: The human introduces themselves as Junie.\n",
      "AI: Nice to meet you, Junie! How can I assist you today?\n",
      "Human: I live in Munich\n",
      "AI: That's great to know, Junie! How can I assist you with information or tasks related to Munich?\n",
      "Human: What's my name?\n",
      "AI: Your name is Junie.\n",
      "Human: I live in Munich\n",
      "AI: Yes, you mentioned earlier that you live in Munich. Is there anything specific you would like to know or discuss about Munich?\n",
      "Human:I live in Munich\n",
      "You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, you mentioned that you live in Munich. Is there anything specific you would like to know or discuss about the city?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"I live in Munich\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbea242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are a helpful AI assistant talking to a human.\n",
      "\n",
      "System: Junie introduces themselves to the AI. The AI responds by greeting Junie and offering assistance. Junie mentions they live in Munich, to which the AI acknowledges and offers help with information or tasks related to Munich.\n",
      "Human: What's my name?\n",
      "AI: Your name is Junie.\n",
      "Human: I live in Munich\n",
      "AI: Yes, you mentioned earlier that you live in Munich. Is there anything specific you would like to know or discuss about Munich?\n",
      "Human: I live in Munich\n",
      "AI: Yes, you mentioned that you live in Munich. Is there anything specific you would like to know or discuss about the city?\n",
      "Human:What's my name?\n",
      "You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Junie. How can I assist you today?'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(question=\"What's my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3babe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: Junie introduces themselves and the AI responds by saying it's nice to meet them and asks how it can assist. Junie shares that they live in Munich, and the AI expresses admiration for the city's beauty and culture, mentioning popular attractions and asking what Junie enjoys most about living there.\\nHuman: What's my name?\\nAI: I'm sorry, I do not have access to personal information such as your name. How can I assist you today?\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
